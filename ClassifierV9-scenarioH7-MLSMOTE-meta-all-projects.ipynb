{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Jacob, addition\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# originals\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv \n",
    "import string\n",
    "import nltk \n",
    "import re \n",
    "import time\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import sys\n",
    "import warnings\n",
    "from os import path\n",
    "import ast\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score, average_precision_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn.metrics import jaccard_score\n",
    "import sklearn.metrics as skm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from skmultilearn.adapt import MLkNN\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from skmultilearn.adapt import BRkNNaClassifier\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "\n",
    "pd.options.display.max_seq_items = 2000\n",
    "pd.options.display.max_colwidth = 90\n",
    "pd.options.display.max_rows = 999\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Importing required Library\n",
    "import random\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_dataset(n_sample=1000):\n",
    "    ''' \n",
    "    Create an unevenly distributed sample data set multilabel  \n",
    "    classification using make_classification function\n",
    "    \n",
    "    args\n",
    "    nsample: int, Number of sample to be created\n",
    "    \n",
    "    return\n",
    "    X: pandas.DataFrame, feature vector dataframe with 10 features \n",
    "    y: pandas.DataFrame, target vector dataframe with 5 labels\n",
    "    '''\n",
    "    X, y = make_classification(n_classes=5, class_sep=2, \n",
    "                           weights=[0.1,0.025, 0.205, 0.008, 0.9], n_informative=3, n_redundant=1, flip_y=0,\n",
    "                           n_features=10, n_clusters_per_class=1, n_samples=1000, random_state=10)\n",
    "    y = pd.get_dummies(y, prefix='class')\n",
    "    return pd.DataFrame(X), y\n",
    "\n",
    "def get_tail_label(df):\n",
    "    \"\"\"\n",
    "    Give tail label colums of the given target dataframe\n",
    "    \n",
    "    args\n",
    "    df: pandas.DataFrame, target label df whose tail label has to identified\n",
    "    \n",
    "    return\n",
    "    tail_label: list, a list containing column name of all the tail label\n",
    "    \"\"\"\n",
    "    columns = df.columns\n",
    "    n = len(columns)\n",
    "    irpl = np.zeros(n)\n",
    "    for column in range(n):\n",
    "        #print(column)\n",
    "        irpl[column] = df[columns[column]].value_counts()[1]\n",
    "        #print(irpl[column])\n",
    "    irpl = max(irpl)/irpl\n",
    "    mir = np.average(irpl)\n",
    "    tail_label = []\n",
    "    for i in range(n):\n",
    "        if irpl[i] > mir:\n",
    "            tail_label.append(columns[i])\n",
    "    return tail_label\n",
    "\n",
    "def get_index(df):\n",
    "    \"\"\"\n",
    "    give the index of all tail_label rows\n",
    "    args\n",
    "    df: pandas.DataFrame, target label df from which index for tail label has to identified\n",
    "    \n",
    "    return\n",
    "    index: list, a list containing index number of all the tail label\n",
    "    \"\"\"\n",
    "    tail_labels = get_tail_label(df)\n",
    "    index = set()\n",
    "    for tail_label in tail_labels:\n",
    "        sub_index = set(df[df[tail_label]==1].index)\n",
    "        index = index.union(sub_index)\n",
    "    return list(index)\n",
    "\n",
    "def get_minority_instace(X, y):\n",
    "    \"\"\"\n",
    "    Give minority dataframe containing all the tail labels\n",
    "    \n",
    "    args\n",
    "    X: pandas.DataFrame, the feature vector dataframe\n",
    "    y: pandas.DataFrame, the target vector dataframe\n",
    "    \n",
    "    return\n",
    "    X_sub: pandas.DataFrame, the feature vector minority dataframe\n",
    "    y_sub: pandas.DataFrame, the target vector minority dataframe\n",
    "    \"\"\"\n",
    "    #print(y)\n",
    "    index = get_index(y)\n",
    "    #print(index)\n",
    "    X_sub = X[X.index.isin(index)].reset_index(drop = True)\n",
    "    y_sub = y[y.index.isin(index)].reset_index(drop = True)\n",
    "    return X_sub, y_sub\n",
    "\n",
    "def nearest_neighbour(X):\n",
    "    \"\"\"\n",
    "    Give index of 5 nearest neighbor of all the instance\n",
    "    \n",
    "    args\n",
    "    X: np.array, array whose nearest neighbor has to find\n",
    "    \n",
    "    return\n",
    "    indices: list of list, index of 5 NN of each element in X\n",
    "    \"\"\"\n",
    "    nbs=NearestNeighbors(n_neighbors=3,metric='euclidean',algorithm='kd_tree').fit(X) #n_neighbors=3 mockito and n_neighbors=5 all\n",
    "    euclidean,indices= nbs.kneighbors(X)\n",
    "    return indices\n",
    "\n",
    "def MLSMOTE(X,y, n_sample):\n",
    "    \"\"\"\n",
    "    Give the augmented data using MLSMOTE algorithm\n",
    "    \n",
    "    args\n",
    "    X: pandas.DataFrame, input vector DataFrame\n",
    "    y: pandas.DataFrame, feature vector dataframe\n",
    "    n_sample: int, number of newly generated sample\n",
    "    \n",
    "    return\n",
    "    new_X: pandas.DataFrame, augmented feature vector data\n",
    "    target: pandas.DataFrame, augmented target vector data\n",
    "    \"\"\"\n",
    "    indices2 = nearest_neighbour(X)\n",
    "    n = len(indices2)\n",
    "    new_X = np.zeros((n_sample, X.shape[1]))\n",
    "    target = np.zeros((n_sample, y.shape[1]))\n",
    "    for i in range(n_sample):\n",
    "        reference = random.randint(0,n-1)\n",
    "        neighbour = random.choice(indices2[reference,1:])\n",
    "        all_point = indices2[reference]\n",
    "        nn_df = y[y.index.isin(all_point)]\n",
    "        ser = nn_df.sum(axis = 0, skipna = True)\n",
    "        target[i] = np.array([1 if val>2 else 0 for val in ser])\n",
    "        ratio = random.random()\n",
    "        gap = X.loc[reference,:] - X.loc[neighbour,:]\n",
    "        new_X[i] = np.array(X.loc[reference,:] + ratio * gap)\n",
    "    new_X = pd.DataFrame(new_X, columns=X.columns)\n",
    "    target = pd.DataFrame(target, columns=y.columns)\n",
    "    new_X = pd.concat([X, new_X], axis=0)\n",
    "    target = pd.concat([y, target], axis=0)\n",
    "    return new_X, target\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#organizing data_frame to issue order\n",
    "import codecs\n",
    "def organize(binaryBodyTitle):\n",
    "\n",
    "    try:\n",
    "        #data = pd.read_csv('file1.csv',skiprows=line)\n",
    "        #data_classes = pd.read_csv( binaryBodyTitle, header = 0, sep=';')\n",
    "        #jabref50 has non utf-8 chars\n",
    "        #data_classes = pd.read_csv( binaryBodyTitle, header = 0, sep=';', encoding= 'unicode_escape')\n",
    "        data_classes = pd.read_csv( binaryBodyTitle, header = 0, sep=';' )\n",
    "\n",
    "    except:\n",
    "        print ('number of columns varying. Skipping bad lines!')\n",
    "        print ('file nme:',binaryBodyTitle)\n",
    "        if (binaryBodyTitle.find('jabref') == -1):\n",
    "            data_classes = pd.read_csv(binaryBodyTitle, header = 0, sep=';', error_bad_lines=False)\n",
    "        else:\n",
    "            #data_classes = pd.read_csv( binaryBodyTitle, header = 0, sep=';')\n",
    "            reviews = []\n",
    "            with open(binaryBodyTitle, 'rt') as f:\n",
    "                  r = csv.reader(f, delimiter=\";\")\n",
    "                    \n",
    "                  for i in r:\n",
    "                      reviews.append(i)\n",
    "                  data_classes = pd.DataFrame(reviews)\n",
    "                    \n",
    "\n",
    "        #jabref50 has non utf-8 chars\n",
    "        #data_classes = pd.read_csv(binaryBodyTitle, header = 0, sep=';', error_bad_lines=False, encoding= 'unicode_escape')\n",
    "\n",
    "    # OBS!!!!!\n",
    "    #line 62 mockito was deleted wrong number of columns!\n",
    "    #line 1923 rxjava was deleted wrong number of columns!\n",
    "    \n",
    "    \n",
    "    ## Code implemented below before modifications by Jacob ##\n",
    "    # del data_classes['prIssue']\n",
    "    # del data_classes['issueTitle']\n",
    "    # del data_classes['issueBody']\n",
    "    \n",
    "    # these renames are listed in the order that the original name appears in the list of headers\n",
    "    # coming in from the binary file\n",
    "    # data_classes.rename(columns={ 'pr': 'prNumber',                                   \n",
    "    #                               'Title': 'prTitle',                                 \n",
    "    #                               'Body': 'prBody',                                   \n",
    "    #                               'issue': 'issueNumber',                             \n",
    "    #                               'issueComments': 'prComments',                      \n",
    "    #                               'issueTitleLink': 'issueTitle',                     \n",
    "    #                               'issueBodyLink': 'issueBody',                       \n",
    "    #                               'issueCommentsLink': 'issue_Comments',              \n",
    "    #                               'Comments': 'prCodeReviewComments' }, inplace=True) \n",
    "    \n",
    "    # categories = data_classes.columns.values.tolist()\n",
    "    \n",
    "    \n",
    "    # this list must match the headers coming in from the binary file in name and order, including\n",
    "    # with the renames above\n",
    "    # data_classes = data_classes[[ 'pr', 'Util', 'NLP', 'APM', 'Network', 'DB', 'Interpreter', 'Logging', \n",
    "    #                               'Thread', 'DataStructure', 'i18n', 'DevOps', 'Logic',  \n",
    "    #                               'Microservices', 'ML', 'Test', 'Search', 'IO', 'UI', 'Parser', 'Security',\n",
    "    #                               'Cloud', 'BigData', 'App', 'GIS', 'Title', 'Body', 'prIssue', 'issue', \n",
    "    #                               'issueTitle', 'issueBody', 'issueComments', 'issueTitleLink', 'issueBodyLink', \n",
    "    #                               'issueCommentsLink', 'isPR', 'isTrain', 'commitMessage', 'Comments']]  \n",
    "\n",
    "\n",
    "    ## Code above after modifications by Jacob ##\n",
    "    # these renames are listed in the order that the original name appears in the list of headers\n",
    "    # coming in from the binary file\n",
    "    data_classes.rename(columns={ 'pr': 'prNumber',                                   \n",
    "                                  'Title': 'prTitle',                                 \n",
    "                                  'Body': 'prBody',                                   \n",
    "                                  'issue': 'issueNumber',                             \n",
    "                                  'issueComments': 'prComments',                      \n",
    "                                  #'issueTitleLink': 'issueTitle',                     \n",
    "                                  #'issueBodyLink': 'issueBody',                       \n",
    "                                  'issueCommentsLink': 'issue_Comments',              \n",
    "                                  'Comments': 'prCodeReviewComments',\n",
    "                                #'Data Structure': 'DataStructure',\n",
    "                            #'Big Data': 'BigData'\n",
    "                                }, inplace=True) \n",
    "    categories_ini = data_classes.columns.values.tolist()\n",
    "    print('Initial categories:',categories_ini)\n",
    " \n",
    "    \n",
    "    # DANGER! old experiments may nott have all this labels!!!\n",
    "    if 'Utility' not in data_classes.columns:\n",
    "        data_classes['Utility'] = 0\n",
    "    if 'Natural Language Processing' not in data_classes.columns:\n",
    "        data_classes['Natural Language Processing'] = 0\n",
    "    if 'Application Performance Manager' not in data_classes.columns:\n",
    "        data_classes['Application Performance Manager'] = 0\n",
    "    if 'Network' not in data_classes.columns:\n",
    "        data_classes['Network'] = 0\n",
    "    if 'Database' not in data_classes.columns:\n",
    "        data_classes['Database'] = 0\n",
    "    if 'Interpreter' not in data_classes.columns:\n",
    "        data_classes['Interpreter'] = 0\n",
    "    if 'Multi Thread' not in data_classes.columns:\n",
    "        data_classes['Multi Thread'] = 0\n",
    "    if 'Error Handling' not in data_classes.columns:\n",
    "        data_classes['Error Handling'] = 0\n",
    "    if 'Logging' not in data_classes.columns:\n",
    "        data_classes['Logging'] = 0\n",
    "    if 'Language' not in data_classes.columns:\n",
    "        data_classes['Language'] = 0\n",
    "    if 'Data Structure' not in data_classes.columns:\n",
    "        data_classes['Data Structure'] = 0\n",
    "    if 'Software Development and IT Operations' not in data_classes.columns:\n",
    "        data_classes['Software Development and IT Operations'] = 0\n",
    "    if 'Internationalization' not in data_classes.columns:\n",
    "        data_classes['Internationalization'] = 0\n",
    "    if 'Setup' not in data_classes.columns:\n",
    "        data_classes['Setup'] = 0\n",
    "    if 'Logic' not in data_classes.columns:\n",
    "        data_classes['Logic'] = 0\n",
    "    if 'Microservices' not in data_classes.columns:\n",
    "        data_classes['Microservices'] = 0\n",
    "    if 'Machine Learning' not in data_classes.columns:\n",
    "        data_classes['Machine Learning'] = 0\n",
    "    if 'Test' not in data_classes.columns:\n",
    "        data_classes['Test'] = 0\n",
    "    if 'Search' not in data_classes.columns:\n",
    "        data_classes['Search'] = 0\n",
    "    if 'Input and Output' not in data_classes.columns:\n",
    "        data_classes['Input and Output'] = 0\n",
    "    if 'User Interface' not in data_classes.columns:\n",
    "        data_classes['User Interface'] = 0\n",
    "    if 'Parser' not in data_classes.columns:\n",
    "        data_classes['Parser'] = 0\n",
    "    if 'Security' not in data_classes.columns:\n",
    "        data_classes['Security'] = 0\n",
    "    if 'Cloud' not in data_classes.columns:\n",
    "        data_classes['Cloud'] = 0\n",
    "    if 'Big Data' not in data_classes.columns:\n",
    "        data_classes['Big Data'] = 0\n",
    "    if 'Event Handling' not in data_classes.columns:\n",
    "        data_classes['Event Handling'] = 0\n",
    "    if 'Application' not in data_classes.columns:\n",
    "        data_classes['Application'] = 0\n",
    "    if 'Geographic Information System' not in data_classes.columns:\n",
    "        data_classes['Geographic Information System'] = 0\n",
    "    if 'Multimedia' not in data_classes.columns:\n",
    "        data_classes['Multimedia'] = 0\n",
    "    if 'Computer Graphics' not in data_classes.columns:\n",
    "        data_classes['Computer Graphics'] = 0\n",
    "    if 'Operation System' not in data_classes.columns:\n",
    "        data_classes['Operation System'] = 0\n",
    "\n",
    "    # standardize labels \n",
    "    data_classes.rename(columns={ 'Utility': 'Util',\n",
    "                                 'Natural Language Processing':'NLP',\n",
    "                                 'Application Performance Manager':'APM',\n",
    "                                 'Network':'Network',\n",
    "                                 'Database':'DB',\n",
    "                                 'Interpreter':'Interpreter',\n",
    "                                 'Multi Thread': 'Thread',\n",
    "                                 'Error Handling':'Error Handling',\n",
    "                                 'Logging':'Logging',\n",
    "                                 'Language':'Lang',\n",
    "                                 'Data Structure':'Data Structure',\n",
    "                                 'Software Development and IT Operations':'DevOps',\n",
    "                                 'Internationalization':'i18n',\n",
    "                                 'Setup':'Setup',\n",
    "                                 'Logic':'Logic',\n",
    "                                 'Microservices':'Microservices',\n",
    "                                 'Machine Learning':'ML',\n",
    "                                 'Test':'Test',\n",
    "                                 'Search':'Search',\n",
    "                                 'Input and Output':'IO',\n",
    "                                 'User Interface':'UI',\n",
    "                                 'Parser':'Parser',\n",
    "                                 'Security':'Security',\n",
    "                                 'Cloud':'Cloud',\n",
    "                                 'Big Data':'Big Data',\n",
    "                                 'Event Handling':'Event Handling',\n",
    "                                 'Application':'App',\n",
    "                                 'Geographic Information System':'GIS',\n",
    "                                 'Multimedia':'Multimedia',\n",
    "                                 'Operation System':'OS',\n",
    "                                 'Computer Graphics':'CG'\n",
    "                                 }, inplace=True) \n",
    "    \n",
    "    categories = data_classes.columns.values.tolist()\n",
    "    print('categories:',categories)\n",
    "    \n",
    "    # this list must match the headers coming in from the binary file in name and order, including\n",
    "    # with the renames above\n",
    "#    data_classes = data_classes[[ 'prNumber', 'Util', 'NLP', 'APM', 'Network', 'DB', 'Interpreter', 'Logging', \n",
    "#                                  'Thread', 'DataStructure', 'i18n', 'DevOps', 'Logic',\n",
    "#                                  'Microservices', 'ML', 'Test', 'Search', 'IO', 'UI', 'Parser', 'Security',\n",
    "#                                  'Cloud', 'BigData', 'App', 'GIS', 'prTitle', 'prBody', 'prIssue', 'issueNumber', \n",
    "#                                  'issueTitle', 'issueBody', 'prComments', 'issueTitleLink', 'issueBodyLink', \n",
    "#                                  'issue_Comments', 'isPR', 'isTrain', 'commitMessage', 'prCodeReviewComments']]    \n",
    "\n",
    "    data_classes = data_classes[ categories]    \n",
    "\n",
    "    \n",
    "    data_classes['issueNumber'] = data_classes['issueNumber'].astype('Int64')\n",
    "    print('before filtering out empty classes',data_classes.shape)\n",
    "    \n",
    "    #find rows with parse error\n",
    "    data_classes_error = data_classes.loc[pd.isnull(data_classes.loc[:,'Util'])]\n",
    "    print('rows filtered out empty classes (parse error)',data_classes_error.shape)\n",
    "    \n",
    "    col_data_classes = len(data_classes.columns)\n",
    "\n",
    "    if (len(data_classes_error) > 0):\n",
    "        data_classes_fixed= data_classes_error.iloc[:,0].str.split(';', expand=True)\n",
    "        print('rows fixed after new parse - empty classes (parse error)',data_classes_fixed.shape)\n",
    "\n",
    "        col_data_classes_fixed = len(data_classes_fixed.columns)\n",
    "        \n",
    "        #removing rows with problems \n",
    "        data_classes.dropna(subset = [\"Util\"], inplace=True)\n",
    "        print('after filtering out empty classes',data_classes.shape)\n",
    "        \n",
    "        print('len columns data_classes:',col_data_classes)\n",
    "        print('len columns data_classes_fixed:',col_data_classes_fixed)\n",
    "        \n",
    "        if (col_data_classes == col_data_classes_fixed):\n",
    "            \n",
    "            #names =['prNumber','DB','Interpreter','Logging','Thread','DataStructure','DevOps','i18n','Logic',\n",
    "            #        'Microservices','ML','Test','Search','IO','UI','Parser','Security','Cloud','BigData','App',\n",
    "            #        'GIS','Util','NLP','APM','Network','prTitle','prBody','prIssue','issueNumber','issueTitle',\n",
    "            #        'issueBody','prComments','issueTitleLink','issueBodyLink','issue_Comments','isPR','isTrain',\n",
    "            #        'commitMessage','prCodeReviewComments']                     \n",
    "            #data_classes_fixed.columns = names\n",
    "            data_classes_fixed.columns = categories\n",
    "\n",
    "            #drop data with error after parsing\n",
    "            index_names = data_classes_fixed[ (data_classes_fixed['Util'] != '0') & (data_classes_fixed['Util'] != '1') |\n",
    "                                     (data_classes_fixed['NLP'] != '0') & (data_classes_fixed['NLP'] != '1') |\n",
    "                                     (data_classes_fixed['APM'] != '0') & (data_classes_fixed['APM'] != '1') |\n",
    "                                     (data_classes_fixed['Network'] != '0') & (data_classes_fixed['Network'] != '1') |\n",
    "                                     (data_classes_fixed['DB'] != '0') & (data_classes_fixed['DB'] != '1') |\n",
    "                                     (data_classes_fixed['Interpreter'] != '0') & (data_classes_fixed['Interpreter'] != '1') |\n",
    "                                     (data_classes_fixed['Logging'] != '0') & (data_classes_fixed['Logging'] != '1') |\n",
    "                                     (data_classes_fixed['Thread'] != '0') & (data_classes_fixed['Thread'] != '1') |\n",
    "                                     (data_classes_fixed['Data Structure'] != '0') & (data_classes_fixed['Data Structure'] != '1') |\n",
    "                                     (data_classes_fixed['i18n'] != '0') & (data_classes_fixed['i18n'] != '1') |\n",
    "\n",
    "                                     (data_classes_fixed['DevOps'] != '0') & (data_classes_fixed['DevOps'] != '1') |\n",
    "                                     (data_classes_fixed['Logic'] != '0') & (data_classes_fixed['Logic'] != '1') |\n",
    "                                     (data_classes_fixed['Microservices'] != '0') & (data_classes_fixed['Microservices'] != '1') |\n",
    "                                     (data_classes_fixed['ML'] != '0') & (data_classes_fixed['ML'] != '1') |\n",
    "                                     (data_classes_fixed['Test'] != '0') & (data_classes_fixed['Test'] != '1') |\n",
    "                                     (data_classes_fixed['Search'] != '0') & (data_classes_fixed['Search'] != '1') |\n",
    "                                     (data_classes_fixed['IO'] != '0') & (data_classes_fixed['IO'] != '1') |\n",
    "                                     (data_classes_fixed['UI'] != '0') & (data_classes_fixed['UI'] != '1') |\n",
    "                                     (data_classes_fixed['Parser'] != '0') & (data_classes_fixed['Parser'] != '1') |\n",
    "                                     (data_classes_fixed['Security'] != '0') & (data_classes_fixed['Security'] != '1') |\n",
    "                                     (data_classes_fixed['Cloud'] != '0') & (data_classes_fixed['Cloud'] != '1') |\n",
    "                                     (data_classes_fixed['Big Data'] != '0') & (data_classes_fixed['Big Data'] != '1') |\n",
    "                                     (data_classes_fixed['App'] != '0') & (data_classes_fixed['App'] != '1') |\n",
    "                                     (data_classes_fixed['GIS'] != '0') & (data_classes_fixed['GIS'] != '1') |\n",
    "                                     (data_classes_fixed['Error Handling'] != '0') & (data_classes_fixed['Error Handling'] != '1') |\n",
    "                                     (data_classes_fixed['Event Handling'] != '0') & (data_classes_fixed['Event Handling'] != '1') |\n",
    "                                     (data_classes_fixed['Lang'] != '0') & (data_classes_fixed['Lang'] != '1') |\n",
    "                                     (data_classes_fixed['Setup'] != '0') & (data_classes_fixed['Setup'] != '1') |\n",
    "                                     (data_classes_fixed['Multimedia'] != '0') & (data_classes_fixed['Multimedia'] != '1') |\n",
    "                                     (data_classes_fixed['OS'] != '0') & (data_classes_fixed['OS'] != '1') |\n",
    "                                      (data_classes_fixed['CG'] != '0') & (data_classes_fixed['CG'] != '1')\n",
    "                                            ].index\n",
    "\n",
    "            # drop these given row\n",
    "            # indexes from dataFrame\n",
    "            data_classes_fixed.drop(index_names, inplace = True)\n",
    "            print('data fixed after dropping parse fix errors',data_classes_fixed.shape)\n",
    "\n",
    "            #back to float\n",
    "            data_classes_fixed['Util'] = data_classes_fixed['Util'].astype(str).astype('Float64')\n",
    "            data_classes_fixed['NLP'] = data_classes_fixed['NLP'].astype(str).astype('Float64')\n",
    "            data_classes_fixed['APM'] = data_classes_fixed['APM'].astype(str).astype('Float64')\n",
    "            data_classes_fixed['Network'] = data_classes_fixed['Network'].astype(str).astype('Float64')\n",
    "            data_classes_fixed['DB'] = data_classes_fixed['DB'].astype(str).astype('Float64')\n",
    "            data_classes_fixed['Interpreter'] = data_classes_fixed['Interpreter'].astype(str).astype('Float64')\n",
    "            data_classes_fixed['Logging'] = data_classes_fixed['Logging'].astype(str).astype('Float64')\n",
    "            data_classes_fixed['Thread'] = data_classes_fixed['Thread'].astype(str).astype('Float64')\n",
    "            data_classes_fixed['Data Structure'] = data_classes_fixed['Data Structure'].astype(str).astype('Float64')\n",
    "            data_classes_fixed['i18n'] = data_classes_fixed['i18n'].astype(str).astype('Float64')\n",
    "            data_classes_fixed['DevOps'] = data_classes_fixed['DevOps'].astype(str).astype('Float64')\n",
    "            data_classes_fixed['Logic'] = data_classes_fixed['Logic'].astype(str).astype('Float64')\n",
    "            data_classes_fixed['Microservices'] = data_classes_fixed['Microservices'].astype(str).astype('Float64')\n",
    "            data_classes_fixed['ML'] = data_classes_fixed['ML'].astype(str).astype('Float64')\n",
    "            data_classes_fixed['Test'] = data_classes_fixed['Test'].astype(str).astype('Float64')\n",
    "            data_classes_fixed['Search'] = data_classes_fixed['Search'].astype(str).astype('Float64')\n",
    "            data_classes_fixed['IO'] = data_classes_fixed['IO'].astype(str).astype('Float64')\n",
    "            data_classes_fixed['UI'] = data_classes_fixed['UI'].astype(str).astype('Float64')\n",
    "            data_classes_fixed['Parser'] = data_classes_fixed['Parser'].astype(str).astype('Float64')\n",
    "            data_classes_fixed['Security'] = data_classes_fixed['Security'].astype(str).astype('Float64')\n",
    "            data_classes_fixed['Cloud'] = data_classes_fixed['Cloud'].astype(str).astype('Float64')\n",
    "            data_classes_fixed['Big Data'] = data_classes_fixed['Big Data'].astype(str).astype('Float64')\n",
    "            data_classes_fixed['App'] = data_classes_fixed['App'].astype(str).astype('Float64')\n",
    "            data_classes_fixed['GIS'] = data_classes_fixed['GIS'].astype(str).astype('Float64')\n",
    "            data_classes_fixed['Error Handling'] = data_classes_fixed['Error Handling'].astype(str).astype('Float64')\n",
    "            data_classes_fixed['Event Handling'] = data_classes_fixed['Event Handling'].astype(str).astype('Float64')\n",
    "            data_classes_fixed['Lang'] = data_classes_fixed['Lang'].astype(str).astype('Float64')\n",
    "            data_classes_fixed['Setup'] = data_classes_fixed['Setup'].astype(str).astype('Float64')\n",
    "            data_classes_fixed['Multimedia'] = data_classes_fixed['Multimedia'].astype(str).astype('Float64')\n",
    "            data_classes_fixed['OS'] = data_classes_fixed['OS'].astype(str).astype('Float64')\n",
    "            data_classes_fixed['CG'] = data_classes_fixed['CG'].astype(str).astype('Float64')\n",
    "\n",
    "            # appending fixed rows\n",
    "            data_classes_new = data_classes.append(data_classes_fixed)\n",
    "            print('after appending fixed rows',data_classes_new.shape)\n",
    "\n",
    "            return data_classes_new\n",
    "        \n",
    "        else:\n",
    "            print('fixing parse errors failed')\n",
    "\n",
    "            return data_classes\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        print('no parse errors found')\n",
    "        return data_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare():\n",
    "\n",
    "    proj_name       = \"jabref50_2\"\n",
    "    print('================================')\n",
    "    print('processing:', proj_name)\n",
    "\n",
    "    # input\n",
    "    binaryBodyTitle_jabref50 = working_dir + \"OSSPRMapper/outputs/\" + proj_name + '/' + proj_name + '_' + \"binaryBodyTitleV9d.csv\"\n",
    "    print( \"Input Binary File: \" + binaryBodyTitle_jabref50 )\n",
    "\n",
    "    data_classes_jabref50 = organize(binaryBodyTitle_jabref50)\n",
    "    print('shape:',data_classes_jabref50.shape)\n",
    "    print('finishing:', proj_name)\n",
    "    print('================================')\n",
    "\n",
    "    #proj_name       = \"guava_2\"\n",
    "\n",
    "    # input\n",
    "    #binaryBodyTitle_guava = working_dir + \"OSSPRMapper/outputs/\" + proj_name + '/' + proj_name + '_' + \"binaryBodyTitle.csv\"\n",
    "    #print( \"Input Binary File: \" + binaryBodyTitle_guava )\n",
    "\n",
    "    #data_classes_guava = organize(binaryBodyTitle_guava)\n",
    "\n",
    "    #proj_name       = \"rxjava_2\"\n",
    "\n",
    "    # input\n",
    "    #binaryBodyTitle_rxjava = working_dir + \"OSSPRMapper/outputs/\" + proj_name + '/' + proj_name + '_' + \"binaryBodyTitle.csv\"\n",
    "    #print( \"Input Binary File: \" + binaryBodyTitle_rxjava )\n",
    "\n",
    "    #data_classes_rxjava = organize(binaryBodyTitle_rxjava)\n",
    "\n",
    "    #proj_name       = \"mockito_2\"\n",
    "\n",
    "    # input\n",
    "    #binaryBodyTitle_mockito = working_dir + \"OSSPRMapper/outputs/\" + proj_name + '/' + proj_name + '_' + \"binaryBodyTitle.csv\"\n",
    "    #print( \"Input Binary File: \" + binaryBodyTitle_mockito )\n",
    "\n",
    "    #data_classes_mockito = organize(binaryBodyTitle_mockito)\n",
    "\n",
    "    #proj_name       = \"presto_2\"\n",
    "\n",
    "    # input\n",
    "    #binaryBodyTitle_presto = working_dir + \"OSSPRMapper/outputs/\" + proj_name + '/' + proj_name + '_' + \"binaryBodyTitle.csv\"\n",
    "    #print( \"Input Binary File: \" + binaryBodyTitle_presto )\n",
    "\n",
    "    #data_classes_presto = organize(binaryBodyTitle_presto)\n",
    "\n",
    "    proj_name       = \"powertoys\"\n",
    "    print('================================')\n",
    "    print('processing:', proj_name)\n",
    "\n",
    "    # input\n",
    "    binaryBodyTitle_powertoys = working_dir + \"OSSPRMapper/outputs/\" + proj_name + '/' + proj_name + '_' + \"binaryBodyTitle.csv\"\n",
    "    print( \"Input Binary File: \" + binaryBodyTitle_powertoys )\n",
    "\n",
    "    data_classes_powertoys = organize(binaryBodyTitle_powertoys)\n",
    "    print('shape:',data_classes_powertoys.shape)\n",
    "    print('finishing:', proj_name)\n",
    "    print('================================')\n",
    " \n",
    "    proj_name       = \"audacity\"\n",
    "    print('================================')\n",
    "    print('processing:', proj_name)\n",
    "\n",
    "    # input\n",
    "    binaryBodyTitle_audacity = working_dir + \"OSSPRMapper/outputs/\" + proj_name + '/' + proj_name + '_' + \"binaryBodyTitle.csv\"\n",
    "    print( \"Input Binary File: \" + binaryBodyTitle_audacity )\n",
    "\n",
    "    data_classes_audacity = organize(binaryBodyTitle_audacity)\n",
    "    print('shape:',data_classes_audacity.shape)\n",
    "    print('finishing:', proj_name)\n",
    "    print('================================')\n",
    "\n",
    "    #proj_name       = \"rmca\" #v2\n",
    "    #print('================================')\n",
    "    #print('processing:', proj_name)\n",
    "\n",
    "    # input\n",
    "    #binaryBodyTitle_rmca= working_dir + \"OSSPRMapper/outputs/\" + proj_name + '/' + proj_name + '_' + \"binaryBodyTitlev2.csv\"\n",
    "    #print( \"Input Binary File: \" + binaryBodyTitle_rmca )\n",
    " \n",
    "    #data_classes_rmca = organize(binaryBodyTitle_rmca)\n",
    "    #print('shape:',data_classes_rmca.shape)\n",
    "    #print('finishing:', proj_name)\n",
    "    #print('================================')\n",
    "\n",
    "    #proj_name       = \"cronos\"\n",
    "    #print('================================')\n",
    "    #print('processing:', proj_name)\n",
    "    \n",
    "    # input\n",
    "    #binaryBodyTitle_cronos= working_dir + \"OSSPRMapper/outputs/\" + proj_name + '/' + proj_name + '_' + \"binaryBodyTitle.csv\"\n",
    "    #print( \"Input Binary File: \" + binaryBodyTitle_cronos )\n",
    "\n",
    "    #data_classes_cronos = organize(binaryBodyTitle_cronos)\n",
    "    #print('shape:',data_classes_cronos.shape)\n",
    "    #print('finishing:', proj_name)\n",
    "    #print('================================')\n",
    "     \n",
    "    #data_classes_jabref50 = pd.read_csv( '/Users/fd252/OneDrive/Research4/MSRExt/OSSPRMapper/outputs/jabref50/jabref50_binaryBodyTitle.csv', header = 0, sep=';' )\n",
    "    #data_classes_guava = pd.read_csv( '/Users/fd252/OneDrive/Research4/MSRExt/OSSPRMapper/outputs/guava/guava_binaryBodyTitle.csv', header = 0, sep=';' )\n",
    "    #data_classes_rxjava = pd.read_csv( '/Users/fd252/OneDrive/Research4/MSRExt/OSSPRMapper/outputs/rxjava/rxjava_binaryBodyTitle.csv', header = 0, sep=';' )\n",
    "    #data_classes_mockito = pd.read_csv( '/Users/fd252/OneDrive/Research4/MSRExt/OSSPRMapper/outputs/mockito/mockito_binaryBodyTitle.csv', header = 0, sep=';' )\n",
    "    #data_classes_presto = pd.read_csv( '/Users/fd252/OneDrive/Research4/MSRExt/OSSPRMapper/outputs/presto/presto_binaryBodyTitle.csv', header = 0, sep=';' )\n",
    "\n",
    "\n",
    "\n",
    "    #data_classes_jabref50.dtypes\n",
    "\n",
    "    #data_classes_jabref50.head()\n",
    "\n",
    "    data_classes_jabref50[\"prNumber\"] = data_classes_jabref50[\"prNumber\"].map(str)\n",
    "    #data_classes_guava[\"prNumber\"] = data_classes_guava[\"prNumber\"].map(str)\n",
    "    #data_classes_rxjava[\"prNumber\"] = data_classes_rxjava[\"prNumber\"].map(str)\n",
    "    #data_classes_mockito[\"prNumber\"] = data_classes_mockito[\"prNumber\"].map(str)\n",
    "    #data_classes_presto[\"prNumber\"] = data_classes_presto[\"prNumber\"].map(str)\n",
    "    \n",
    "    data_classes_powertoys[\"prNumber\"] = data_classes_powertoys[\"prNumber\"].map(str)\n",
    "    data_classes_audacity[\"prNumber\"] = data_classes_audacity[\"prNumber\"].map(str)\n",
    "    #data_classes_rmca[\"prNumber\"] = data_classes_rmca[\"prNumber\"].map(str)\n",
    "    #data_classes_cronos[\"prNumber\"] = data_classes_cronos[\"prNumber\"].map(str)\n",
    "    \n",
    "    #data_classes_jabref50.dtypes\n",
    "\n",
    "    data_classes_jabref50['prNumber'] = 'jabref50-' + data_classes_jabref50['prNumber'].astype(str)\n",
    "    #data_classes_guava['prNumber'] = 'guava-' + data_classes_guava['prNumber'].astype(str)\n",
    "    #data_classes_rxjava['prNumber'] = 'rxjava-' + data_classes_rxjava['prNumber'].astype(str)\n",
    "    #data_classes_mockito['prNumber'] = 'mockito-' + data_classes_mockito['prNumber'].astype(str)\n",
    "    #data_classes_presto['prNumber'] = 'presto-' + data_classes_presto['prNumber'].astype(str)\n",
    "\n",
    "    data_classes_powertoys['prNumber'] = 'powertoys-' + data_classes_powertoys['prNumber'].astype(str)\n",
    "    data_classes_audacity['prNumber'] = 'audacity-' + data_classes_audacity['prNumber'].astype(str)\n",
    "    #data_classes_rmca['prNumber'] = 'rmca-' + data_classes_rmca['prNumber'].astype(str)\n",
    "    #data_classes_cronos['prNumber'] = 'cronos-' + data_classes_cronos['prNumber'].astype(str)\n",
    "\n",
    "    #data_classes_jabref50.head()\n",
    "\n",
    "    #data_classes_all = pd.concat([data_classes_jabref50, data_classes_guava, data_classes_rxjava, data_classes_mockito, data_classes_presto], axis=0)\n",
    "    #data_classes_all = pd.concat([data_classes_jabref50,data_classes_powertoys, data_classes_audacity, data_classes_rmca, data_classes_cronos], axis=0)\n",
    "    data_classes_all = pd.concat([data_classes_jabref50,data_classes_powertoys, data_classes_audacity], axis=0)\n",
    "    #data_classes_all.tail()\n",
    "\n",
    "    del data_classes_all[\"Utlity\"]\n",
    "    del data_classes_all[\"Untility\"]\n",
    "    del data_classes_all[\"Logi\"]\n",
    "\n",
    "    data_classes_all = data_classes_all[[ 'prNumber', 'Util','NLP','APM','Network','DB','Interpreter','Thread','Error Handling','Logging','Lang','Data Structure',\n",
    "          'DevOps','i18n','Setup','Logic','Microservices','ML','Test','Search','IO','UI',\n",
    "          'Parser','Security','Cloud','Big Data','Event Handling','App','GIS','OS','Multimedia','CG','prTitle', 'prBody', 'prIssue', 'issueNumber', \n",
    "                                  'issueTitle', 'issueBody', 'prComments', 'issueTitleLink', 'issueBodyLink', \n",
    "                                  'issue_Comments', 'isPR', 'isTrain', 'commitMessage', 'prCodeReviewComments']] \n",
    "    \n",
    "#'Thread', \n",
    "    print(\"saving:\",binaryBodyTitle)\n",
    "    data_classes_all.to_csv( binaryBodyTitle, sep=';' )\n",
    "    \n",
    "    print(\"================data_classes_all AFTER CONCAT\\n=========================\")\n",
    "    print(data_classes_all.shape)\n",
    "\n",
    "    \n",
    "    return data_classes_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_classes = prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering issues with PRs\n",
    "def filtering(data_classes):\n",
    "    \n",
    "    print('before filtering out isTrain == 0',data_classes.shape)\n",
    "\n",
    "    IssuePRDataset = data_classes[data_classes[\"isTrain\"] == 0]\n",
    "    \n",
    "    print('after filtering out isTrain == 0',IssuePRDataset.shape)\n",
    "\n",
    "\n",
    "    #invalid number of issue = NaN\n",
    "    # IssuePRDataset = IssuePRDataset.drop([1805])\n",
    "\n",
    "    categories = IssuePRDataset.columns.values.tolist()\n",
    "    \n",
    "    return categories, IssuePRDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RQ1.a - o quão sensível o resultado é em relação ao algoritmo? \n",
    "#vários algoritmos - BinaryRelevance\n",
    "#todas as palavras, bootstrap, unigram \n",
    "#somente o título\n",
    "def dataset_config(IssuePRDataset):\n",
    "    # ORIGINAL\n",
    "    # data_test1 = IssuePRDataset[['issueNumber','prNumber','issueTitle','Google Common', \n",
    "    #                              'Test', 'SO', 'IO', 'UI', 'Network', 'Security', \n",
    "    #                              'OpenOffice Documents', 'Database', 'Utils', 'PDF', \n",
    "    #                              'Logging', 'Latex']].copy()\n",
    "    \n",
    "    # WORKS WITH NEW INPUTS\n",
    "    # data_test1 = IssuePRDataset[['issueNumber','prNumber','issueTitle', 'Test','IO', 'UI', 'Network', 'Security', 'Logging' ]].copy() \n",
    "\n",
    "    # only classes printed in values after concatenation!!!!!!\n",
    "    data_test1 = IssuePRDataset[[ 'issueNumber','prNumber','issueTitle','issueBody', 'prTitle', 'prBody',\n",
    "                             'issueTitleLink','issueBodyLink','commitMessage','prComments',\n",
    "                                 'Util', 'NLP', 'APM', 'Network', 'DB', 'Interpreter','Thread',\n",
    "       'DevOps', 'i18n', 'Setup', 'Logic', 'Microservices', 'ML', 'Test',\n",
    "       'Search', 'IO', 'UI', 'Parser', 'Security', 'Cloud', 'Big Data',\n",
    "       'Event Handling', 'App', 'GIS', 'OS', 'Multimedia', 'CG']].copy()\n",
    "    # all classes (USE olny those printed after concatenation)\n",
    "    #'Util','NLP','APM','Network','DB','Interpreter','Thread','Error Handling','Logging','Lang','Data Structure',\n",
    "    #      'DevOps','i18n','Setup','Logic','Microservices','ML','Test','Search','IO','UI',\n",
    "    #      'Parser','Security','Cloud','Big Data','Event Handling','App','GIS','OS','Multimedia','CG'\n",
    "\n",
    "    #print(type(data_test1))\n",
    "    #data_test1['corpus'] = IssuePRDataset['issueTitle'] + IssuePRDataset['issueBody']\n",
    "    data_test1[\"corpus\"] = data_test1[\"issueBody\"].map(str)\n",
    "\n",
    "    # rxjava 2489 terms\n",
    "    # mockito 598\n",
    "    # presto 4\n",
    "    # guava 1140\n",
    "    # jabref 740\n",
    "    \n",
    "    #data_test1[\"corpus\"] = data_test1[\"issueTitle\"].map(str) + ' ' + data_test1[\"issueBody\"].map(str) + ' ' + data_test1[\"prTitle\"].map(str) + ' ' + data_test1[\"prBody\"].map(str)\n",
    "    # rxjava 3002 terms\n",
    "    \n",
    "    del data_test1[\"issueTitle\"]\n",
    "    del data_test1[\"issueBody\"]\n",
    "    del data_test1[\"prTitle\"]\n",
    "    del data_test1[\"prBody\"]\n",
    "    del data_test1[\"issueTitleLink\"]\n",
    "    del data_test1[\"issueBodyLink\"]\n",
    "    del data_test1[\"commitMessage\"]\n",
    "    del data_test1[\"prComments\"]\n",
    "\n",
    "    print('before filtering out empty corpus',data_test1.shape)\n",
    "    data_test1.dropna(subset = [\"corpus\"], inplace=True)\n",
    "    \n",
    "    data_test1['corpus'] = data_test1['corpus'].str.replace(\"nan\",' ')\n",
    "    print('after filtering out empty corpus',data_test1.shape)\n",
    "\n",
    "    #removing utils because we won't to predict a so simple API that is basically used in all PRs\n",
    "    #del data_test1[\"Util\"]\n",
    "\n",
    "    data_test1 = data_test1.reset_index(drop=True)\n",
    "    \n",
    "    return data_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing text\n",
    "\n",
    "#We first convert the comments to lower-case \n",
    "#then use custom made functions to remove html-tags, punctuation and non-alphabetic characters from the TitleBody.\n",
    "\n",
    "def clean_data(data_test1):\n",
    "    if not sys.warnoptions:\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    def cleanHtml(sentence):\n",
    "        cleanr = re.compile('<.*?>')\n",
    "        cleantext = re.sub(cleanr, ' ', str(sentence))\n",
    "        return cleantext\n",
    "\n",
    "    def cleanPunc(sentence): #function to clean the word of any punctuation or special characters\n",
    "        cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "        cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "        cleaned = cleaned.strip()\n",
    "        cleaned = cleaned.replace(\"\\n\",\" \")\n",
    "        return cleaned\n",
    "\n",
    "    def keepAlpha(sentence):\n",
    "        alpha_sent = \"\"\n",
    "        for word in sentence.split():\n",
    "            alpha_word = re.sub('[^a-z A-Z]+', ' ', word)\n",
    "            alpha_sent += alpha_word\n",
    "            alpha_sent += \" \"\n",
    "        alpha_sent = alpha_sent.strip()\n",
    "        return alpha_sent\n",
    "\n",
    "    #function pra remover palavras com menos de 3 tokens\n",
    "\n",
    "    data_test1['corpus'] = data_test1['corpus'].str.lower()\n",
    "    data_test1['corpus'] = data_test1['corpus'].apply(cleanHtml)\n",
    "    data_test1['corpus'] = data_test1['corpus'].apply(cleanPunc)\n",
    "    data_test1['corpus'] = data_test1['corpus'].apply(keepAlpha)\n",
    "    \n",
    "    return data_test1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### removing stopwords\n",
    "\n",
    "def remove_stop_words():\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words.update(['nan','pr','zero','one','two','three','four','five','six','seven','eight','nine','ten','may','also','across','among','beside','however','yet','within','jabref','org','github','com','md','https','ad','changelog','','joelparkerhenderson','localizationupd',' localizationupd','localizationupd ','i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the','Mr', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now'])\n",
    "    #stop_words.update(['i', 'me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\",\"Mr\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"])\n",
    "\n",
    "    re_stop_words = re.compile(r\"\\b(\" + \"|\".join(stop_words) + \")\\\\W\", re.I)\n",
    "\n",
    "    return re_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeStopWords(sentence, re_stop_words):\n",
    "    #global re_stop_words\n",
    "    #print(sentence)\n",
    "    return re_stop_words.sub(\" \", sentence)\n",
    "\n",
    "#removing words with less than 3 characters\n",
    "#data_classes['titleBody'] = data_classes['titleBody'].str.findall('\\w{3,}').str.join(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_stem(data_test1):\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    \n",
    "    def stemming(sentence):\n",
    "        stemSentence = \"\"\n",
    "        for word in sentence.split():\n",
    "            stem = stemmer.stem(word)\n",
    "            stemSentence += stem\n",
    "            stemSentence += \" \"\n",
    "        stemSentence = stemSentence.strip()\n",
    "        return stemSentence\n",
    "    \n",
    "    data_test1['corpus'] = data_test1['corpus'].apply(stemming)\n",
    "    #print(data_test1['corpus'])\n",
    "    \n",
    "    return data_test1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-ID\n",
    "def run_tf_idf(data, configurationTFIDF, num_feature, tfIDFoutputFile):\n",
    "    #we need to text max_feature with 10, 20, 25, 50 \n",
    "    #, max_features=num_feature\n",
    "    vectorizer = TfidfVectorizer(strip_accents='unicode', analyzer='word', ngram_range = configurationTFIDF, max_features=num_feature)\n",
    "        \n",
    "    tf_idf_results = vectorizer.fit_transform(data['corpus'])\n",
    "\n",
    "    features = vectorizer.get_feature_names()\n",
    "\n",
    "    #print(features)\n",
    "\n",
    "    scores = (tf_idf_results.toarray())\n",
    "    output_tf_idf = pd.DataFrame(scores)\n",
    "    \n",
    "    output_tf_idf = pd.concat([data['issueNumber'], output_tf_idf], axis=1)\n",
    "\n",
    "    output_tf_idf.to_csv(tfIDFoutputFile, encoding='utf-8', header=False, index=False, sep=',')\n",
    "\n",
    "\n",
    "    # remove words occuring less than 5 times\n",
    "    #tfidf = TfidfVectorizer(min_df=5)\n",
    "    #you can also remove common words:\n",
    "\n",
    "    # remove words occuring in more than half the documents\n",
    "    #tfidf = TfidfVectorizer(max_df=0.5)\n",
    "    #you can also remove stopwords like this:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analyzing frequency of TOP 50 terms\n",
    "\n",
    "def analyze_top(data, termFrequencyTop50):\n",
    "    docs = data['corpus'].tolist()\n",
    "\n",
    "    cv = CountVectorizer()\n",
    "    cv_fit=cv.fit_transform(docs)\n",
    "\n",
    "    #print(cv.get_feature_names())\n",
    "    #print(cv_fit.toarray())\n",
    "\n",
    "    word_list = cv.get_feature_names()   \n",
    "\n",
    "    count_list = cv_fit.toarray().sum(axis=0)\n",
    "    term_frequency = dict(zip(word_list,count_list))\n",
    "\n",
    "    a = sorted(term_frequency.items(), key=lambda x: x[1], reverse=True) \n",
    "    \n",
    "    print('SIZE OF TERMS', len(a))\n",
    "    \n",
    "    top50 = a[:50]\n",
    "    df_frequency = pd.DataFrame(top50, columns =['term', 'frequency'])  \n",
    "    #df_frequency = pd.DataFrame(a, columns =['term', 'frequency'])  \n",
    "\n",
    "\n",
    "    print(df_frequency)\n",
    "    #print(a)\n",
    "\n",
    "    df_frequency.to_csv(termFrequencyTop50, encoding='utf-8', header=False, index=False, sep=',')\n",
    "\n",
    "    sns.set(font_scale = 2)\n",
    "    plt.figure(figsize=(18,17))\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(\"Frequency of terms \")\n",
    "    plt.ylabel('term', fontsize=20)\n",
    "    plt.xlabel('frequency', fontsize=20)\n",
    "    ax = sns.barplot(x=\"frequency\", y=\"term\", data=df_frequency)\n",
    "    \n",
    "    return docs, a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging features TF-IDF with data_frame\n",
    "def merging(data_test1, tfIDFoutputFile):\n",
    "    feature = pd.read_csv(tfIDFoutputFile, header=None, sep=\",\")\n",
    "    feature.rename(columns={0: 'issueNumber'}, inplace=True)\n",
    "\n",
    "    data_classifier = data_test1.join(feature, lsuffix='issueNumber', rsuffix='issueNumber')\n",
    "\n",
    "    categories = data_classifier.columns.values.tolist()\n",
    "    \n",
    "    return data_classifier, categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(predictions, probabilities, y_test):\n",
    "    \n",
    "    y_pred = predictions.values\n",
    "    y_proba = probabilities.values\n",
    "\n",
    "    #receiving the y_test true value from each pull request\n",
    "    y_true = y_test.to_numpy()\n",
    "\n",
    "    print(\"Accuracy Score\")\n",
    "    acc_ml = accuracy_score(y_true, y_pred)\n",
    "    print(acc_ml)\n",
    "\n",
    "    print(\"---------\")\n",
    "    print(\"\")\n",
    "\n",
    "    print(\"Accuracy Score not normalized\")\n",
    "    acc_score = accuracy_score(y_true, y_pred, normalize=False)\n",
    "    print(acc_score)\n",
    "\n",
    "    print(\"---------\")\n",
    "    print(\"\")\n",
    "\n",
    "    print(\"zero_one_loss\")\n",
    "    zeroOne = zero_one_loss(y_true, y_pred)\n",
    "    print(zeroOne)\n",
    "\n",
    "    print(\"---------\")\n",
    "    print(\"\")\n",
    "\n",
    "    print(\"Fmeasure Score\")\n",
    "    fmeasure_score = f1_score(y_true,y_pred, average='micro')\n",
    "    #fmeasure_score = f1_score(y_true,y_pred, average='macro')\n",
    "    print(fmeasure_score)\n",
    "\n",
    "    print(\"---------\")\n",
    "    print(\"\")\n",
    "\n",
    "    #AUC-PR\n",
    "    print(\"AUC-PR\")\n",
    "    pr_score = average_precision_score(y_true,y_proba,average='micro')\n",
    "    print(pr_score)\n",
    "    #pr_score = average_precision_score(y_true,y_proba,average='macro')\n",
    "\n",
    "    print(\"---------\")\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "    print(\"hamming loss average\")\n",
    "    hamming_loss = skm.hamming_loss(y_true, y_pred)\n",
    "    print(hamming_loss)\n",
    "\n",
    "    print(\"---------\")\n",
    "    print(\"\")\n",
    "\n",
    "    print(\"Jaccard samples\")\n",
    "    jaccard_score_samples = jaccard_score(y_true, y_pred, average='samples')\n",
    "    print(jaccard_score_samples)\n",
    "\n",
    "    print(\"---------\")\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "    print(\"Jaccard macro\")\n",
    "    jaccard_macro = jaccard_score(y_true, y_pred, average='micro')\n",
    "    print(jaccard_macro)\n",
    "    #jaccard_score(y_true, y_pred, average=None)\n",
    "\n",
    "    print(\"---------\")\n",
    "    print(\"\")\n",
    "\n",
    "    return y_true, y_proba, y_pred, acc_ml, acc_score, zeroOne, fmeasure_score, pr_score, hamming_loss, jaccard_score_samples, jaccard_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classes(probability, y_true, y_test):\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    average_precision = dict()\n",
    "\n",
    "    n_classes = y_test.shape[1]\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        precision[i], recall[i], _ = precision_recall_curve(y_true[:, i], probability[:, i])\n",
    "        average_precision[i] = average_precision_score(y_true[:, i], probability[:, i])\n",
    "\n",
    "    precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(y_true.ravel(),probability.ravel())\n",
    "\n",
    "    average_precision[\"micro\"] = average_precision_score(y_true, probability, average=\"micro\")\n",
    "\n",
    "    print('Average precision score, micro-averaged over all classes: {0:0.2f}'\n",
    "          .format(average_precision[\"micro\"]))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.step(recall['micro'], precision['micro'], where='post')\n",
    "\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title(\n",
    "        'Average precision score, micro-averaged over all classes: AP={0:0.2f}'\n",
    "        .format(average_precision[\"micro\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "def confusion_matrix(y_true, y_pred, confusionMatrix, i, proj_name, labels):\n",
    "\n",
    "    data = multilabel_confusion_matrix(y_true, y_pred)\n",
    "    #print('CM:',type(data))\n",
    "    \n",
    "    #labels = ['Util', 'NLP', 'APM', 'Network', 'DB', 'Interpreter',\n",
    "    #                              'Logging', 'Thread', 'Data Structure', 'i18n', \n",
    "    #                              'DevOps', 'Logic', 'interpreter', 'Microservices', 'ML',\n",
    "    #                              'Test', 'Search', 'IO', 'UI', 'Parser', 'Security',\n",
    "    #                              'Cloud', 'Big Data', 'App', 'GIS']        \n",
    "\n",
    "    metrics = pd.DataFrame()\n",
    "    line = []\n",
    "    dataLine = \"\"\n",
    "    dataLine = \"Label, TN, FP, FN, TP\"\n",
    "    line.append((dataLine))\n",
    "\n",
    "    #for j in range (0,12):\n",
    "    #print('CM:', len(labels))\n",
    "    #print('Data:', data.shape)\n",
    "    for j in range (0,len(labels)):\n",
    "        #print(j)\n",
    "        row = data[j]\n",
    "        dataLine=\"\"\n",
    "        dataLine = labels[j] \n",
    "        #print(dataLine)\n",
    "        for x in np.nditer(row):\n",
    "            dataLine = dataLine + \",\" + str(x)\n",
    "            #print(dataLine)\n",
    "        line.append((dataLine))\n",
    "        #print(line)\n",
    "        \n",
    "        metrics = pd.DataFrame(line)\n",
    "    \n",
    "    print(line)\n",
    "    metrics.to_csv(confusionMatrix + str(i) +'.csv' , encoding='utf-8', header=True, index=False , sep=',')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the model \n",
    "\n",
    "def build_model(test_type):\n",
    "    clf = BinaryRelevance(classifier=RandomForestClassifier(criterion='entropy',max_depth= 50, min_samples_leaf= 1, min_samples_split= 3, n_estimators= 50), require_dense = [False, True])\n",
    "\n",
    "\n",
    "    if test_type == \"DecisionTree\":\n",
    "        clf = BinaryRelevance(classifier=DecisionTreeClassifier(), require_dense = [False, True])\n",
    "        #clf = ClassifierChain(classifier=DecisionTreeClassifier(), require_dense = [False, True])\n",
    "    if test_type == \"LogisticRegression\":\n",
    "        clf = BinaryRelevance(classifier=LogisticRegression(random_state=0), require_dense = [False, True])\n",
    "        #clf = ClassifierChain(classifier=LogisticRegression(random_state=0), require_dense = [False, True])\n",
    "    if test_type == \"RandomForest\": \n",
    "        clf = BinaryRelevance(classifier=RandomForestClassifier(criterion='entropy',max_depth= 50, min_samples_leaf= 1, min_samples_split= 3, n_estimators= 50), require_dense = [False, True])\n",
    "        #clf = ClassifierChain(classifier=RandomForestClassifier(criterion='entropy',max_depth= 50, min_samples_leaf= 1, min_samples_split= 3, n_estimators= 50), require_dense = [False, True])\n",
    "    if test_type == \"MLPClassifier\":\n",
    "        clf = BinaryRelevance(classifier=MLPClassifier(hidden_layer_sizes=(150,100,50), max_iter=300,activation = 'relu',solver='adam',random_state=1), require_dense = [False, True])\n",
    "        #clf = ClassifierChain(classifier=MLPClassifier(hidden_layer_sizes=(150,100,50), max_iter=300,activation = 'relu',solver='adam',random_state=1), require_dense = [False, True])\n",
    "    if test_type == \"MLkNN\":\n",
    "        clf = BinaryRelevance(MLkNN(k=3))\n",
    "        #clf = ClassifierChain(classifier=MLkNN(k=3))\n",
    "\n",
    "    #This three works without probability\n",
    "    if test_type == \"LinearSVC\":\n",
    "        clf = BinaryRelevance(classifier=LinearSVC(), require_dense = [False, True])\n",
    "    if test_type == \"GaussianNB\":\n",
    "        clf = BinaryRelevance(classifier=GaussianNB(), require_dense = [False, True])\n",
    "    if test_type == \"RidgeClassifierCV\":\n",
    "        clf = BinaryRelevance(classifier=RidgeClassifierCV(alphas=[1e-3, 1e-2, 1e-1, 1]), require_dense = [False, True]) \n",
    "    if test_type == \"BRkNNaClassifier\":\n",
    "        clf = BinaryRelevance(BRkNNaClassifier(k=3))\n",
    "\n",
    "        \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metrics(y_true, y_pred, acc_ml,acc_score,zeroOne,pr_score,hamming_loss,jaccard_score_samples,jaccard_macro, modelMatrix, metrics_by_class, i, configurationTFIDF ,num_feature ,stop_word ,size_test,test_type, proj_name, names, report):\n",
    "\n",
    "    line=[] \n",
    "    # line to csv report file\n",
    "    \n",
    "    prec, rec, fscore, sup = precision_recall_fscore_support(y_true,y_pred, average='micro')\n",
    "\n",
    "\n",
    "    arr = [acc_ml,acc_score,zeroOne,pr_score,hamming_loss,jaccard_score_samples,jaccard_macro,prec,rec, fscore]\n",
    "    columns = ['Accuracy','Acc-Score','zero_one_loss','AUC-PR','hamming loss average','Jaccard samples','Jaccard macro','Precision','Recall','Fmeasure']\n",
    "  \n",
    "    df_metrics2 = pd.DataFrame([arr],columns=columns)\n",
    "    print(df_metrics2)\n",
    "\n",
    "    print(\"---------\")\n",
    "    print(\"\")\n",
    "\n",
    "    x = precision_recall_fscore_support(y_true,y_pred, average=None)\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "\n",
    "    df_metrics_by_class = pd.DataFrame.from_records(x, columns=names, index=['precision','recall','f-measure','samples_tested'])\n",
    "    print(df_metrics_by_class)\n",
    "\n",
    "    print(\"---------\")\n",
    "    print(\"\")\n",
    "\n",
    "    df_metrics2.to_csv(modelMatrix+str(i)+'.csv', encoding='utf-8', header=True, index=False, sep=',')    \n",
    "\n",
    "    df_metrics_by_class.to_csv(metrics_by_class+str(i)+'.csv', encoding='utf-8', header=True, index=False, sep=',')    \n",
    "\n",
    "    dataLine = \"\"\n",
    "    dataLine = \"tf-IDFMin, tf-IDFMax, #_TopTerms,Stop_Word,Train/Test_Size,Algorithm,Accuracy_Score,Accuracy_Score_not_normalized,zero_one_loss, AUC-PR,hamming_loss_avg,Jaccard_samples,Jaccard_macro,Precision,Recall,Fmeasure_Score, i\"\n",
    "    line.append((dataLine))\n",
    "    dataLine =  str(configurationTFIDF) + \",\" + str(num_feature) + \",\" + stop_word + \",\" + str(size_test) + \",\" + str(test_type) + \",\" + str(acc_ml) + \",\"+ str(acc_score) + \",\"+ str(zeroOne) + \",\" + str(pr_score) + \",\"+ str(hamming_loss) + \",\"+ str(jaccard_score_samples) + \",\"+ str(jaccard_macro)+\",\" + str(prec)+\",\"+str(rec)+\",\"+str(fscore)+\",\"+str(i) \n",
    "    line.append((dataLine))\n",
    "    print(line)\n",
    "\n",
    "    metrics = pd.DataFrame(line)\n",
    "    metrics.to_csv(report+str(i)+'.csv', encoding='utf-8', header=False, index=False, sep=',')    \n",
    "    #np.savetxt(r'./experiment/report'+ str(configurationTFIDF) + str(num_feature) + stop_word + str(size_test)+ str(test_type)+str(i)+'.txt', metrics.values, fmt='%s', delimiter=',')\n",
    "    #np.savetxt(r'./experiment/new/'+proj_name+'/report'+ str(configurationTFIDF) + str(num_feature) + stop_word + str(size_test)+ str(test_type)+str(i)+'.txt', metrics.values, fmt='%s', delimiter=',')\n",
    "\n",
    "    return prec, rec, fscore, sup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def persist_data(configurationTFIDF ,num_feature , stop_word , size_test , test_type , acc_ml , \n",
    "           acc_score , zeroOne , pr_score, hamming_loss, jaccard_score_samples, \n",
    "           jaccard_macro , prec , rec, fscore, i):\n",
    "    now = datetime.datetime.now()\n",
    "    date_str = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    templateData = pd.read_csv(dfTeste_output, sep=',')\n",
    "    \n",
    "    #print (\"Current date and time : \")\n",
    "    #print (now.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    headerdf = ['date_time','tf-IDF', '#_TopTerms','Stop_Word','Train/Test_Size','Algorithm','Accuracy_Score',\n",
    "                'Accuracy_Score_not_normalized','zero_one_loss', 'AUC-PR','hamming_loss_avg','Jaccard_samples',\n",
    "                'Jaccard_macro','Precision','Recall','Fmeasure_Score','i']\n",
    "\n",
    "\n",
    "    tup = ( date_str,str(configurationTFIDF) ,str(num_feature) , stop_word , str(size_test) , str(test_type) , str(acc_ml) , \n",
    "           str(acc_score) , str(zeroOne) , str(pr_score) , str(hamming_loss) , str(jaccard_score_samples) , \n",
    "           str(jaccard_macro) , str(prec) , str(rec) , str(fscore) ,str(i))\n",
    "\n",
    "    #print(\"tupla:\", tup)\n",
    "    #print(len(tup))\n",
    "\n",
    "    list_tup  = [ date_str,str(configurationTFIDF) ,str(num_feature) , stop_word , str(size_test) , str(test_type) , str(acc_ml) , \n",
    "           str(acc_score) , str(zeroOne) , str(pr_score) , str(hamming_loss) , str(jaccard_score_samples) , \n",
    "           str(jaccard_macro) , str(prec) , str(rec) , str(fscore) ,str(i)]\n",
    "\n",
    "\n",
    "    dfTeste = pd.DataFrame.from_records(data=[tup], columns=[headerdf])\n",
    "\n",
    "    data_list = templateData.values.tolist()\n",
    "    data_list.append(list_tup)\n",
    "    new_data = pd.DataFrame(data_list)  \n",
    "    #for row in templateData.itertuples():\n",
    "    #    print(row)\n",
    "\n",
    "    new_data.to_csv( dfTeste_output, encoding='utf-8', index=False, sep=',', header=headerdf)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_split(dataset_smote, test_type, confusionMatrix, modelMatrix, metrics_by_class, configurationTFIDF ,num_feature ,stop_word ,size_test, proj_name, final_columns, report, predictions_result, probabilities_result, classifierFeatureInput):\n",
    "    train = []\n",
    "    test = []\n",
    "\n",
    "    max_f = final_columns[len(final_columns)-1]\n",
    "    min_f = final_columns[0]\n",
    "    print('min:',min_f,' max:',max_f)\n",
    "    \n",
    "    #our_X = data_classifier.iloc[:,16:916]\n",
    "    #our_y = data_classifier.iloc[:,2:14]\n",
    "    #dataset = pd.concat([our_y,our_X], axis=1)\n",
    "    #dataset_smote = pd.concat([dataset, y_X_res], axis=0)\n",
    "    \n",
    "    #X = data_classifier\n",
    "    X = dataset_smote\n",
    "    splits = 10\n",
    "    rs = ShuffleSplit(n_splits=splits, test_size= size_test, random_state=52)\n",
    "    rs.get_n_splits(X)\n",
    "\n",
    "    for train_index, test_index in rs.split(X):\n",
    "         #print(\"%s %s\" % (train_index, test_index))\n",
    "         train.append(train_index)\n",
    "         test.append(test_index)\n",
    "        \n",
    "    for i in range(0, len(train)):\n",
    "        size_features = len(X.columns)\n",
    "        \n",
    "        size_features = len(X.columns)\n",
    "        \n",
    "        data = dataset_smote.iloc[train[i]]\n",
    "        \n",
    "        #data.to_csv(classifierFeatureInput+'train'+str(i)+'.csv', encoding='utf-8', sep=',')    \n",
    "        \n",
    "        X_train = data.iloc[:,len(final_columns):size_features] # all\n",
    "        y_train = data.loc[:,min_f :max_f] # all           \n",
    "\n",
    "        data = dataset_smote.iloc[test[i]]\n",
    "\n",
    "        #data.to_csv(classifierFeatureInput+'test'+str(i)+'.csv', encoding='utf-8', sep=',')    \n",
    "\n",
    "        \n",
    "        testing_another_project=''\n",
    "        if testing_another_project=='powertoys':\n",
    "            X_test = pd.read_csv( '/Users/fd252/OneDrive/Research4/MSRExt/H3/X_test_powertoys9-H7.csv', header = 0, sep=',')\n",
    "            y_test = pd.read_csv( '/Users/fd252/OneDrive/Research4/MSRExt/H3/Y_test_powertoys9-H7.csv', header = 0, sep=',')\n",
    "            \n",
    "            print(\"================X_test and Y_test=========================\")\n",
    "            print(\"================comming\\n=========================\")\n",
    "            print(\"================from\\n=========================\")\n",
    "            print(\"================different\\n=========================\")\n",
    "            print(\"================project\\n=========================\")\n",
    "            print(\"================!!!!!\\n=========================\")\n",
    "            print('new X_test shape',X_test.shape)\n",
    "            print('new y_test shape',y_test.shape)\n",
    "            print('new X_test cols',X_test.columns)\n",
    "            print('new y_test cols',y_test.columns)\n",
    "        else:\n",
    "            X_test = data.iloc[:,len(final_columns):size_features] # all\n",
    "            y_test = data.loc[:,min_f :max_f] # all \n",
    "\n",
    "            print('old X_test shape',X_test.shape)\n",
    "            print('old y_test shape',y_test.shape)\n",
    "            print('old X_test cols',X_test.columns)\n",
    "            print('old y_test cols',y_test.columns)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #print(\"================y_train\\n=========================\")\n",
    "\n",
    "        #print('Y_train:',y_train)\n",
    "        #print(y_train.columns)\n",
    "        #print(y_train.shape)\n",
    "\n",
    "        #print(\"================X_train\\n=========================\")\n",
    "\n",
    "        #print(X_train.columns)\n",
    "        #print(X_train.shape)\n",
    "        \n",
    "        #print(\"================y_test\\n=========================\")\n",
    "\n",
    "        #print(y_test.columns)\n",
    "        #print(y_test.shape)\n",
    "        \n",
    "        #print(\"================X_test\\n=========================\")\n",
    "\n",
    "        #print(X_test.columns)\n",
    "        #print(X_test.shape)\n",
    "        #print(len(X_test),len(X_test.columns))\n",
    "\n",
    "        categories = y_test.columns.values.tolist()\n",
    "        print('categories y_test:',categories)\n",
    "        ids = y_test.index\n",
    "\n",
    "        classifier_setup = build_model(test_type)\n",
    "    \n",
    "        clf = classifier_setup\n",
    "        \n",
    "        #try:\n",
    "        clf.fit(X_train,y_train)\n",
    "\n",
    "        predict = clf.predict(X_test).toarray()\n",
    "        print (type(predict))\n",
    "        print(predict.shape[0])\n",
    "        print(predict.shape[1])\n",
    "\n",
    "        try:\n",
    "            probability = clf.predict_proba(X_test).toarray()\n",
    "            #print (type(probability))\n",
    "            #print(probability.shape[0])\n",
    "            #print(probability.shape[1])\n",
    "        except:\n",
    "            probability = myArr = np.zeros((len(X_test),len(y_test.columns))) # rows = X_test & columns = y_test !!!\n",
    "\n",
    "        predictions = pd.DataFrame(predict, index=ids, columns=categories) # with header\n",
    "        probabilities = pd.DataFrame(probability, index=ids, columns=categories) # with header\n",
    "\n",
    "        #predictions.to_csv(predictions_result+str(i)+'.csv', encoding='utf-8', sep=',')    \n",
    "        #probabilities.to_csv(probabilities_result+str(i)+'.csv', encoding='utf-8', sep=',')    \n",
    "\n",
    "        #y_pred = predictions.values\n",
    "        #y_proba = probabilities.values\n",
    "\n",
    "        y_true = y_test.to_numpy()\n",
    "\n",
    "        y_true, y_proba, y_pred, acc_ml, acc_score, zeroOne, fmeasure_score, pr_score, hamming_loss, jaccard_score_samples, jaccard_macro = eval_metrics(predictions, probabilities, y_test)\n",
    "\n",
    "        plot_classes(probability, y_true, y_test)\n",
    "\n",
    "        confusion_matrix(y_true, y_pred, confusionMatrix, i, proj_name, final_columns)\n",
    "\n",
    "        prec, rec, fscore, sup = save_metrics(y_true, y_pred, acc_ml,acc_score,zeroOne,pr_score,hamming_loss,jaccard_score_samples,jaccard_macro, modelMatrix, metrics_by_class, i, configurationTFIDF ,num_feature ,stop_word ,size_test,test_type, proj_name, final_columns, report)\n",
    "\n",
    "        persist_data(configurationTFIDF ,num_feature , stop_word , size_test , test_type , acc_ml , \n",
    "           acc_score , zeroOne , pr_score, hamming_loss, jaccard_score_samples, \n",
    "           jaccard_macro , prec , rec, fscore, i)\n",
    "        #except: \n",
    "            #print (\"fit error! all one class\")\n",
    "            #print(y_train.columns)\n",
    "            #print(y_train.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project\n",
    "proj_name       = \"all_2\"\n",
    "working_dir     = \"/Users/fd252/OneDrive/Research4/MSRExt/\"\n",
    "#labels = ['Util', 'NLP', 'APM', 'Network', 'DB', 'Interpreter', 'Logging', \n",
    "#                                  'Thread', 'DataStructure', 'i18n', 'DevOps', 'Logic',\n",
    "#                                  'Microservices', 'ML', 'Test', 'Search', 'IO', 'UI', 'Parser', 'Security',\n",
    "#                                  'Cloud', 'BigData', 'App', 'GIS']\n",
    "            \n",
    "labels = ['Util','NLP','APM','Network','DB','Interpreter','Thread','Error Handling','Logging','Lang','Data Structure',\n",
    "          'DevOps','i18n','Setup','Logic','Microservices','ML','Test','Search','IO','UI',\n",
    "          'Parser','Security','Cloud','Big Data','Event Handling','App','GIS','OS','Multimedia','CG']\n",
    "\n",
    "#BINARY ORDER\n",
    "#pr;Application Performance Manager;Logi;User Interface;Network;Language;Multi Thread;Multimedia;Interpreter;Error Handling;Input and Output;Logging;Data Structure;Computer Graphics;Setup;Logic;Utility;Untility;Geographic Information System;Application;Internationalization;Parser;Database;Event Handling\n",
    "# input\n",
    "\n",
    "binaryBodyTitle = working_dir + \"OSSPRMapper/outputs/\" + proj_name + '/' + proj_name + '_' + \"binaryBodyTitle.csv\"\n",
    "print( \"Input Binary File: \" + binaryBodyTitle )\n",
    "\n",
    "\n",
    "# output\n",
    "output_root_dir = working_dir + \"H7/experiment/new/\"  \n",
    "out_path        = output_root_dir + proj_name + '/' + proj_name + '_'\n",
    "\n",
    "print( \"Output path      : \" + out_path )\n",
    "\n",
    "dfTeste_output  = out_path + \"dfTeste.csv\"\n",
    "print( \"dfTeste output   : \" + dfTeste_output )\n",
    "# UNUSED: loggingFile  = out_path + \"TitleBody3GramTFIDF.txt\"\n",
    "\n",
    "# !! see In[45] for the definitions of these output paths. They are kept here for posterity but must be defined there\n",
    "# tfIDFoutputFile        = out_path + 'tfIDFoutputFile'+ str(configurationTFIDF) + str(num_feature) + stop_word + str(size_test)+ str(test_type)+'.csv'\n",
    "# classifierFeatureInput = out_path + 'train_file_test'+ str(configurationTFIDF) + str(num_feature) + stop_word + str(size_test)+ str(test_type)+'.csv'\n",
    "# termFrequencyTop50     = out_path + 'termFrequencyTop50'+ str(configurationTFIDF) + str(num_feature) + stop_word + str(size_test)+ str(test_type)+'.csv'\n",
    "# predictions_result     = out_path + 'predict_file_'+ str(configurationTFIDF) + str(num_feature) + stop_word + str(size_test)+ str(test_type)+'.csv'\n",
    "# probabilities_result   = out_path + 'probability_file_'+ str(configurationTFIDF) + str(num_feature) + stop_word + str(size_test)+ str(test_type)+'.csv'\n",
    "# modelMatrix            = out_path + 'modelMatrix'+ str(configurationTFIDF) + str(num_feature) + stop_word + str(size_test)+ str(test_type)+'.csv'\n",
    "# metrics_by_class       = out_path + 'metrics_By_Class'+ str(configurationTFIDF) + str(num_feature) + stop_word + str(size_test)+ str(test_type)+'.csv'  \n",
    "# confusionMatrix        = out_path + 'CM'+ str(configurationTFIDF) + str(num_feature) + stop_word + str(size_test)+ str(test_type) \n",
    "\n",
    "#number of shuffles (folds)\n",
    "splits=10\n",
    "\n",
    "#defining paths\n",
    "# loggingFile = './experiment//TitleBody3GramTFIDF.txt'\n",
    "# binaryBodyTitle = './experiment/binaryBodyTitle.csv'\n",
    "template = output_root_dir + proj_name + '/' + 'dfTeste.csv'\n",
    "\n",
    "#configurationTFIDFList = [(1,1)]\n",
    "#configurationTFIDFList = [(1,1),(2,2)]\n",
    "configurationTFIDFList = [(1,1),(2,2),(3,3),(4,4)]\n",
    "#configurationTFIDFList = [(2,2),(3,3),(4,4)]\n",
    "#num_featureList = [25,50,100,500,1000,2500,5000]\n",
    "#num_featureList = [90,179,358,716,895,1432,2864,5728]\n",
    "num_featureList = [895] #MSR\n",
    "\n",
    "\n",
    "#num_featureList = [740] #jabref body 739 v2\n",
    "#num_featureList = [1140] #guava body  1141 v2\n",
    "#num_featureList = [4] #presto body 4 v2\n",
    "#num_featureList = [598] #mockito body 597 v2\n",
    "#num_featureList = [2489] #rxjava body 2436 v2\n",
    "#num_featureList = [2676] #jabref50 body 2676 v2\n",
    "\n",
    "#num_featureList = [228] #jabref title\n",
    "#num_featureList = [6] #guava title\n",
    "#num_featureList = [7] #presto title\n",
    "#num_featureList = [216] #mockito title\n",
    "#num_featureList = [800] #rxjava title\n",
    "#num_featureList = [838] #jabref50 title\n",
    "\n",
    "#num_featureList = [794] #jabref title+body\n",
    "#num_featureList = [1143] #guava title+body\n",
    "#num_featureList = [10] #presto title+body\n",
    "#num_featureList = [654] #mockito title+body\n",
    "#num_featureList = [2615] #rxjava title+body\n",
    "#num_featureList = [2818] #jabref50 title+body\n",
    "\n",
    "#num_featureList = [1336] #jabref title+body+comments\n",
    "#num_featureList = [1204] #guava title+body+comments\n",
    "#num_featureList = [10] #presto title+body+comments\n",
    "#num_featureList = [974] #mockito title+body+comments\n",
    "#num_featureList = [3269] #rxjava title+body+comments\n",
    "#num_featureList = [5622] #jabref50 title+body+comments\n",
    "\n",
    "#size_testList = [0.2]\n",
    "#size_testList = [0.2,0.3]\n",
    "size_testList = [0.2,0.3,0.4]\n",
    "stop_wordList = [\"Yes\"]\n",
    "test_typeList = [\"RandomForest\",\"DecisionTree\",\"LogisticRegression\",\"MLPClassifier\",\"MLkNN\"]\n",
    "#test_typeList = [\"RandomForest\",\"DecisionTree\",\"MLPClassifier\",\"MLkNN\"]\n",
    "#test_typeList = [\"RandomForest\",\"DecisionTree\",\"MLPClassifier\"]\n",
    "#test_typeList = [\"RandomForest\",\"LogisticRegression\",\"DecisionTree\"]\n",
    "#test_typeList = [\"RandomForest\"]\n",
    "\n",
    "testing_another_project=''\n",
    "\n",
    "#examples\n",
    "#configurationTFIDFList = [(1,1),(2,2)]\n",
    "#num_featureList = [25,50]\n",
    "#size_testList = [0.2,0.3]\n",
    "#stop_wordList = [\"Yes\",\"No\"]\n",
    "#test_typeList = [\"RandomForest\",\"DecisionTree\"]\n",
    "\n",
    "configurationTFIDF=(1,1)\n",
    "num_feature=895\n",
    "\n",
    "size_test=0.2\n",
    "\n",
    "#stop_word = stop_wordList[i]\n",
    "stop_word = \"Yes\"\n",
    "\n",
    "test_type = \"RandomForest\"\n",
    "# dont forget to have the file dfTeste.csv ready in the files folder only with the header!\n",
    "\n",
    "def __main__():\n",
    "    \n",
    "    print(\"----------------\") \n",
    "    now = datetime.datetime.now()\n",
    "\n",
    "    \n",
    "    print (\"Current date and time : \")\n",
    "    print (now.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    print(proj_name)\n",
    "    print(\"----------------\") \n",
    "\n",
    "    # getting length of list \n",
    "    lengthT = len(configurationTFIDFList) \n",
    "    lengthF = len(num_featureList) \n",
    "    lengthS = len(size_testList)\n",
    "    lengthY = len(test_typeList)\n",
    "    \n",
    "    #data_classes = organize()\n",
    "    data_classes = prepare()\n",
    "\n",
    "    print('Columns after the concatenation:', data_classes.columns )\n",
    "    \n",
    "    categories, IssuePRDataset = filtering(data_classes)\n",
    "    data_test1 = dataset_config(IssuePRDataset)\n",
    "    data_test1 = clean_data(data_test1)\n",
    "    #print('################# data_test1 after fixing')\n",
    "    #print(data_test1)\n",
    "\n",
    "#   print('1',data_test1['corpus'])\n",
    "\n",
    "    re_stop_words = remove_stop_words()\n",
    "    data_test1['corpus'] = data_test1['corpus'].apply(removeStopWords, re_stop_words=re_stop_words)\n",
    "    data = data_test1\n",
    "#   print('2',data_test1['corpus'])\n",
    "    data_test1 = apply_stem(data)\n",
    "    \n",
    "    print(\"================COLUMNS BEFORE DELETION\\n=========================\")\n",
    "    print('data shape:',data_test1.shape)\n",
    "    nrows = data_test1.shape[0]\n",
    "    nrows_threshold = nrows * 0.9\n",
    "    print('threshold:', nrows_threshold)\n",
    "    print('data_test1 columns:',list(data_test1.columns))\n",
    "    first = labels[0]\n",
    "    print('1o label:',first)\n",
    "    last = labels [len(labels)-1]\n",
    "    print('last label:',last)\n",
    "    no_occurences = data_test1.loc[:,first:last].sum()\n",
    "    #print(type(no_occurences))\n",
    "    print(\"================LABELS\\n=========================\")\n",
    "\n",
    "    print(no_occurences)  #df.loc[:, 'Score'].sum()\n",
    "\n",
    "    last = ' '\n",
    "    setup_first = False \n",
    "    num_with_values = 0\n",
    "    final_columns = []\n",
    "    for i, v in no_occurences.items(): \n",
    "        #print('i;',i)\n",
    "        #print('v;',v)\n",
    "        #if v == 0:\n",
    "        if v < 2:\n",
    "            print ('deleting columns with < 2. ', i, 'occurences:', v)\n",
    "            del data_test1[i]\n",
    "\n",
    "        else:\n",
    "            if v > nrows_threshold:\n",
    "                print ('deleting columns with > ', nrows_threshold, '.', i, 'occurences:', v)\n",
    "                del data_test1[i]\n",
    "\n",
    "            else:\n",
    "                if not setup_first:\n",
    "                    #if v != 0:\n",
    "                    #if v > 1:\n",
    "                    first = i\n",
    "                    print('first element > 0', first)\n",
    "                    setup_first = True\n",
    "\n",
    "                final_columns.append(i)\n",
    "                num_with_values = num_with_values + 1\n",
    "                last = i\n",
    "    print('last element > 0:', last)\n",
    "            \n",
    "    print('classes range:', first,' - ', last, 'total:',num_with_values)\n",
    "    print('final classes (columns):', final_columns)\n",
    "    \n",
    "    if testing_another_project=='powertoys':\n",
    "\n",
    "        print(\"================Limitingt=========================\")\n",
    "        print(\"================column\\n=========================\")\n",
    "        print(\"================compatible\\n=========================\")\n",
    "        print(\"================with\\n=========================\")\n",
    "        print(\"================different\\n=========================\")\n",
    "        print(\"================project\\n=========================\")\n",
    "        print(\"================!!!!!\\n=========================\")\n",
    "        # columns all_2\n",
    "        #['Util', 'NLP', 'APM', 'Network', 'DB', 'Interpreter', 'DevOps', 'i18n', 'Setup', 'Logic', 'Microservices', 'Test', 'Search', 'IO', 'UI', 'Parser', 'Security', 'Big Data', 'Event Handling', 'App', 'GIS', 'OS', 'Multimedia', 'CG']\n",
    "        \n",
    "        # columns powertoys H1\n",
    "        #['APM', 'Interpreter', 'Logging', 'Thread', 'Data Structure', 'i18n', 'Setup', 'Logic', 'Microservices', 'Test', 'Search', 'UI', 'Parser', 'App', 'OS']\n",
    "\n",
    "        del data_test1[\"NLP\"]\n",
    "        del data_test1[\"Network\"]\n",
    "        del data_test1[\"DB\"]\n",
    "        del data_test1[\"DevOps\"]\n",
    "        del data_test1[\"IO\"]\n",
    "        del data_test1[\"Security\"]\n",
    "        del data_test1[\"Big Data\"]\n",
    "        del data_test1[\"Event Handling\"]\n",
    "        del data_test1[\"Multimedia\"]\n",
    "        del data_test1[\"CG\"]\n",
    "        del data_test1[\"GIS\"]\n",
    "\n",
    "    print(\"================COLUMNS AFTER DELETION\\n=========================\")\n",
    "    print('data shape:',data_test1.shape)\n",
    "    #data_test1.to_csv('data_classes.csv', encoding='utf-8', sep=',')    \n",
    "\n",
    "    if num_with_values < 2:\n",
    "        print('Less than 2 valid labels:', num_with_values, ' exiting...')\n",
    "        print('data columns:',data_test1.columns)\n",
    "        sys.exit()\n",
    "\n",
    "    # Iterating the index \n",
    "    # same as 'for i in range(len(list))' \n",
    "    for f in range(lengthF): \n",
    "        print(\"----------------\") \n",
    "        print(num_featureList[f]) \n",
    "        print(\"----------------\") \n",
    "\n",
    "        num_feature=num_featureList[f]\n",
    "\n",
    "        for t in range(lengthT): \n",
    "            print(\"----------------\") \n",
    "            print(num_featureList[f]) \n",
    "            print(configurationTFIDFList[t])\n",
    "            print(\"----------------\") \n",
    "\n",
    "            configurationTFIDF=configurationTFIDFList[t]\n",
    "\n",
    "            tfIDFoutputFile        = out_path + 'tfIDFoutputFile'+ str(configurationTFIDF) + str(num_feature) + stop_word +'.csv'\n",
    "            termFrequencyTop50     = out_path + 'termFrequencyTop50'+ str(configurationTFIDF) + str(num_feature) + stop_word + '.csv'\n",
    "            docs, a = analyze_top(data_test1, termFrequencyTop50)\n",
    "\n",
    "            print('num features discovered automaticaly', len(a))\n",
    "#           print('3',data_test1['corpus'])\n",
    "            #run_tf_idf(data_test1, configurationTFIDF, num_feature, tfIDFoutputFile)\n",
    "            if testing_another_project=='powertoys':\n",
    "                #len(a) = 2054 #Number of geatures of powertoys with corpus = body\n",
    "                run_tf_idf(data_test1, configurationTFIDF, 2054, tfIDFoutputFile)\n",
    "\n",
    "                print(\"================Limitingt=========================\")\n",
    "                print(\"================number of features\\n=========================\")\n",
    "                print(\"================that is comming\\n=========================\")\n",
    "                print(\"================from\\n=========================\")\n",
    "                print(\"================different\\n=========================\")\n",
    "                print(\"================project\\n=========================\")\n",
    "                print(\"================!!!!!\\n=========================\")\n",
    "            else:\n",
    "                run_tf_idf(data_test1, configurationTFIDF, len(a), tfIDFoutputFile)\n",
    "#           print('4',data_test1['corpus'])                 \n",
    "\n",
    "            data_classifier, categories = merging(data_test1, tfIDFoutputFile)     \n",
    "\n",
    "            for s in range(lengthS):\n",
    "                print(\"----------------\") \n",
    "                print(num_featureList[f]) \n",
    "                print(configurationTFIDFList[t]) \n",
    "                print(size_testList[s]) \n",
    "                print(\"----------------\") \n",
    "\n",
    "                size_test=size_testList[s]\n",
    "\n",
    "                for y in range(lengthY):\n",
    "                    print(\"----------------\") \n",
    "                    print(num_featureList[f]) \n",
    "                    print(configurationTFIDFList[t]) \n",
    "                    print(size_testList[s]) \n",
    "                    print(test_typeList[y]) \n",
    "                    print(\"----------------\") \n",
    "\n",
    "                    #stop_word = stop_wordList[i]\n",
    "                    #stop_word = \"Yes\"\n",
    "\n",
    "                    test_type = test_typeList[y]\n",
    "                    \n",
    "                    # tfIDFoutputFile = './experiment/tfIDFoutputFile'+ str(configurationTFIDF) + str(num_feature) + stop_word + str(size_test)+ str(test_type)+'.csv'\n",
    "                    # classifierFeatureInput='./experiment/train_file_test'+ str(configurationTFIDF) + str(num_feature) + stop_word + str(size_test)+ str(test_type)+'.csv'\n",
    "                    # termFrequencyTop50 = './experiment/termFrequencyTop50'+ str(configurationTFIDF) + str(num_feature) + stop_word + str(size_test)+ str(test_type)+'.csv'\n",
    "                    # predictions_result = './experiment/predict_file_'+ str(configurationTFIDF) + str(num_feature) + stop_word + str(size_test)+ str(test_type)+'.csv'\n",
    "                    # probabilities_result = './experiment/probability_file_'+ str(configurationTFIDF) + str(num_feature) + stop_word + str(size_test)+ str(test_type)+'.csv'\n",
    "                    # modelMatrix = './experiment/modelMatrix'+ str(configurationTFIDF) + str(num_feature) + stop_word + str(size_test)+ str(test_type)+'.csv'\n",
    "                    # metrics_by_class = './experiment/metrics_By_Class'+ str(configurationTFIDF) + str(num_feature) + stop_word + str(size_test)+ str(test_type)+'.csv'  \n",
    "                    # confusionMatrix = './experiment/CM'+ str(configurationTFIDF) + str(num_feature) + stop_word + str(size_test)+ str(test_type) \n",
    "                    classifierFeatureInput = out_path + 'train_file_test'+ str(configurationTFIDF) + str(num_feature) + stop_word + str(size_test)+ str(test_type)\n",
    "                    predictions_result     = out_path + 'predict_file_'+ str(configurationTFIDF) + str(num_feature) + stop_word + str(size_test)+ str(test_type)\n",
    "                    probabilities_result   = out_path + 'probability_file_'+ str(configurationTFIDF) + str(num_feature) + stop_word + str(size_test)+ str(test_type)\n",
    "                    modelMatrix            = out_path + 'modelMatrix'+ str(configurationTFIDF) + str(num_feature) + stop_word + str(size_test)+ str(test_type)\n",
    "                    metrics_by_class       = out_path + 'metrics_By_Class'+ str(configurationTFIDF) + str(num_feature) + stop_word + str(size_test)+ str(test_type)  \n",
    "                    confusionMatrix        = out_path + 'CM'+ str(configurationTFIDF) + str(num_feature) + stop_word + str(size_test)+ str(test_type) \n",
    "                    report                 = out_path + 'report'+ str(configurationTFIDF) + str(num_feature) + stop_word + str(size_test)+ str(test_type) \n",
    "                    \n",
    "                    # some rows are with nan. df = df[df['my_var'].notna()] ?\n",
    "                    # or should we change by blank spaces?\n",
    " \n",
    "                    #SMOTE)\n",
    "                    #print(list(data_classifier.columns))\n",
    "                    \n",
    "                    #SMOTE\n",
    "                    limit = len(data_classifier.columns)\n",
    "                    \n",
    "                    print('column limit:', limit)\n",
    "                                        \n",
    "                    our_X = data_classifier.iloc[:,num_with_values+4:limit] # TF-IDF probabilities all\n",
    "                    our_y = data_classifier.iloc[:,2:num_with_values+2] # Expert labels all\n",
    "\n",
    "                    print(\"================our_y AFTER DELETION\\n=========================\")\n",
    "                    print(our_y.shape)\n",
    "                    #print(our_y.columns)\n",
    "                    #our_y.to_csv(classifierFeatureInput+'_our_y.csv', encoding='utf-8', sep=',')    \n",
    "   \n",
    "                    print(\"================our_X AFTER DELETION\\n=========================\")\n",
    "                    print(our_X.shape)\n",
    "                    #print(our_X.columns)\n",
    "\n",
    "                    dataset = pd.concat([our_y,our_X], axis=1)                    \n",
    "                    #dataset.shape\n",
    "\n",
    "                    try:\n",
    "\n",
    "                        X_sub, y_sub = get_minority_instace(our_X, our_y)   #Getting minority instance of that datframe\n",
    "\n",
    "\n",
    "                        X_res,y_res =MLSMOTE(X_sub, y_sub, 100)     #Applying MLSMOTE to augment the dataframe\n",
    "\n",
    "                        y_X_res = pd.concat([y_res,X_res], axis=1)\n",
    "                        #y_X_res.shape\n",
    "\n",
    "                        print(\"================SMOTE \\n=========================\")\n",
    "                        dataset_smote = pd.concat([dataset, y_X_res], axis=0)\n",
    "\n",
    "                    except: \n",
    "                        \n",
    "                        print(\"================SMOTE Failed\\n=========================\")\n",
    "\n",
    "                        dataset_smote = dataset\n",
    "\n",
    "\n",
    "                    print('dataset after smote:',dataset_smote.shape)\n",
    "                    #dataset_smote.to_csv(classifierFeatureInput+'_dataset_smote.csv', encoding='utf-8', sep=',')    \n",
    "                    \n",
    "                    #run_split(dataset_smote, test_type, confusionMatrix, modelMatrix, metrics_by_class, configurationTFIDF ,num_feature ,stop_word ,size_test, proj_name, final_columns, report, predictions_result, probabilities_result, classifierFeatureInput)\n",
    "                    run_split(dataset_smote, test_type, confusionMatrix, modelMatrix, metrics_by_class, configurationTFIDF ,len(a) ,stop_word ,size_test, proj_name, final_columns, report, predictions_result, probabilities_result, classifierFeatureInput)\n",
    "                    \n",
    "    print(\"----------------\") \n",
    "    print( \"Operations complete!\")\n",
    "    now = datetime.datetime.now()\n",
    "\n",
    "    \n",
    "    print (\"Current date and time : \")\n",
    "    print (now.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    print(\"----------------\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "__main__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
